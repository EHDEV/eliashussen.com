+++
title = ""
slug = "resume"
+++

## Elias Hussen  Resume

New York, NY 10029        

646-450-2275

ehussen[at]gmail.com    

---

### EDUCATION

Columbia University – New York, NY			  Sep 2014 – Dec 2016               
Master of Science, Data Science 

Baruch College, NY			  Sep 2007 – Dec 2010               
BBA, Information Systems    


### SELECTED COURSEWORK:

Machine Learning | Neural Networks and Deep Learning | Probability | Statistical Inference and Modeling | Microservice Apps and APIs | Exploratory Data Analysis and Visualization | Translational Bioinformatics | Computer Systems for Data Science.

### SELECTED DATA SCIENCE PROJECTS

**The All Convolutional Net.**  Tools Used: _Python, Theano, Lasagne, Scikit-Learn, Scipy, Numpy, AWS EC2 Elastic GPU_

Implemented the All Convolutional Net, a deep learning architecture that consists solely of convolutional layers. Used the Theano and Lasagne deep learning frameworks; reproduced the results and confirmed the thesis of the paper that max-pooling can be replaced by a convolutional layer with increased stride without loss in accuracy on several image recognition benchmarks. [Link](https://github.com/EHDEV/relaxation_response)

**Artist Recommender System Using Python and Apache Spark.**  Tools Used: _PySpark, MlLib, Python, AWS EMR_

Built a recommender system in PySpark using the Alternating Least Square Matrix Factorization algorithm to model listening behavior of users and recommend new artists based on implicit feedback inferred. [Link](https://github.com/EHDEV/spark_music)

**Relaxation Response (RR) Induced Expression Changes to Genes Associated with Diabetes, Alzheimer's and Obesity.** Tools Used: _R_

Machine learning research on gene expression data of genes that are linked to Diabetes, Alzheimers and Obesity. The aim was to find any set of genes with a statistically significant association to relaxation response activities (yoga, meditation, regular prayers, etc). Trained a Logistic Regression model with L1 & L2 regularization, using a dimensionally reduced gene expression samples to classify among control group, long-term and short-term practitioners of RR activities. Discovered a set of genes linked to the immune system that were significantly elevated in long-term and short-term practitioners of RR as opposed to the control group. [Link](https://github.com/EHDEV/relaxation_response)

**Data Lake and Analytics Platform.** Tools Used: _Snowflake, Python, Apache Airflow, AWS Redshift, S3, SQS, Apache Spark_

A cloud data warehouse along with a collection of high performance data pipelines built to ingest data from disparate sources such as Facebook, Adobe, Google AdManager, YouTube, and other to load into the enterprise data lake and warehouse, transform and make available for analytics.

**Employee Tenure ML Challenge.** Tools Used: _Python, Scikit-Learn, Numpy, Pandas, Matplotlib, Seaborn, Scipy, Jupyter Notebook_

A modeling, and data exploration challenge on real world data for an HR consulting company to analyze and predict the tenure length of employees. [Link](https://github.com/EHDEV/employee_tenure_modeling)

### RECENT WORK EXPERIENCE

**Managing Partner & Head of Machine Learning:**    6irdview (pronounced Bird View)      •      San Jose, CA     •     Dec 2019 – Jun 2020

6irdview is a consulting agency that contracts with clients to develop software and Machine Learning solutions. As a managing partner and head of ML at 6irdview, I was responsible for architecting and building Machine Learning and Data Engineering projects. We successfully built and sold a text classification model trained to qualify a lead into a prospect based on SMS messages received from the lead. The model, built with FastAI, PyTorch and Scikit-Learn, achieved 90+ percent accuracy and was deployed into an API using Flask on a Linode instance.

**Senior Data Engineer:**        Vice Media     •     New York, NY     •     Dec 2018 – July 2019

Contribute to designing, building, and deploying high-performance production platforms to support data warehousing, real-time ETL, and batch big-data processing; help define standards and best practices for enterprise usage.
Occasionally examine the data and become familiar with marketing, finance, sales, etc operations to discover use cases where an AI system would bring value. Build POC Machine Learning models and demo to internal clients.
Translate business data and analytics needs into enterprise data models, ELT pipelines and advanced visualization dashboards.
Develop compelling PoC’s for data solutions using new tools and methods for big data ingestion, processing and analytics. 

**Principal Data Engineer (Consultant):**      Bank of America     •     New York, NY   •    Dec 2016 – Nov 2017

Build and maintain Python packages that consume real time data from a Java REST API, transform, and perform operations. Collaborate with engineers, testers and systems administrators to identify data and analytics requirements and develop practical solutions. 
Contribute to a record linkage Python project to collect records from multiple data sources and perform statistical analysis to identify matching records. 


**Analytics Engineer:**       Unified Social     •     New York, NY     •     Sep 2014 – Sep 2015

Successfully developed and managed an internal reporting Python project, developing the architecture, building, and deploying pipelines that collect ad statistics from Twitter, Facebook, and LinkedIn; transform using Pandas, numpy, and SQL; and pipe into a modeling and visualization platform. 
Collaborated cross-functionally in a team of Engineers, Data Scientists, and Marketing Managers to build, test, and deploy a redshift data warehouse along with required ETL pipelines. 
Processed data for analysis and reporting by developing several Apache PIG and Python scripts to extract massive amounts of unstructured data from S3 and subsequently performed transformations, custom defined operations and loaded the data into a Redshift data warehouse. 
Developed data pipelines, relational objects and SQL queries for analysis through extensive collaboration within the data science team to identify, transform and engineer features that will be fitted into predictive and optimization models. 


**Business Intelligence Analyst:**        SourceMedia     •     New York, NY     •     Dec 2012 – Dec 2013

Worked in tandem with marketing and sales teams to perform deep data analysis to measure and understand subscription churn and retention rates. 
Developed and deployed data pipelines, rich interactive dashboards and visualizations of marketing and financial statistics using SQL, Spotfire and Talend.


**Business Data Analyst:**         Pervasive Software    •     Austin, TX     •     May 2011 -  Aug 2012

Owned the design, development and maintenance of an end-to-end enterprise BI platform that incorporates, data pipelines, visualizations and dashboards as well as a SQL Server data warehouse to support sales and marketing decisions. 
Integrated Pervasive’s Salesforce.com CRM, Zuora SaaS platform, and SQL Server data warehouse by developing a number of complex ETL jobs. 
Collaborated extensively with business users, application developers, and production teams across functional units to identify business data requirements and implement BI solutions.


**Production Support Engineer:**           OnDeck Capital   •   New York, NY	•	  Mar 2010 – Mar 2011

Lead the production support team that supported the company's loan transaction system, CRM, and enterprise data warehouse. Working closely with the finance team, engineered daily and monthly reconciliation pipelines that collect detailed loan transaction data from disparate internal and external data sources, transform, load, analyze and generate detailed reconciliation reports.
Engineered and deployed multiple data pipelines to regularly migrate loan transaction data into an enterprise data warehouse.
Partnered with business users to prepare and analyze business requirements; subsequently generating ad hoc reports and building a financial reconciliation tool made up of SSIS ETL jobs and complex SQL scripts.


### TECHNICAL SKILLS

**Data Engineering:** Data Modeling and Architecture, Data Pipelining, Data Warehouse Design, Dashboarding and Visualization.

**Machine Learning:** NLP, Deep Learning, Classification, Regression, Collaborative Filtering, Clustering, Feature Engineering, Model Selection, Ensemble Learning Methods.

**Statistical Methods:** Regression Models, Hypothesis Testing and Confidence Intervals, Principal Component Analysis, SVD and Dimensionality Reduction.

**Data Visualization:** Matplotlib, Seaborn, Tableau, Domo, D3, HighCharts, ggplot2.

**Software Tools, Frameworks and Programming Languages:** Python, Flask, Django, Scikit-Learn, FastAI, Pytorch, Huggingface Transformers, Keras, Scipy, Numpy, R, SQL, Hadoop (Hive, Pig, MapReduce), Spark (PySpark, MLlib).

**Database**:  Snowflake, Redshift, DynamoDB, MongoDB, PostgreSQL, MySQL.

**AWS:** S3, EC2, Lambda, Redshift, SQS, Glue.
